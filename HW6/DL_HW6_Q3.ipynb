{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zmxo2g4QGjOh"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSXHDbbZLHZ0"
      },
      "source": [
        "# prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-gUZ9ZwLHEH",
        "outputId": "bb5a2cd0-17f9-4817-b4df-0db3b5ff0cc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 18s 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-2-2c2ed39229d7>:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  unlabeld_index = np.ones(y_train.shape, np.bool)\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "unlabeld_index = np.ones(y_train.shape, np.bool)\n",
        "\n",
        "N = 20\n",
        "for i in range(10):\n",
        "  idx = np.where(y_train == i)[0][:N]\n",
        "  unlabeld_index[idx] = 0\n",
        "\n",
        "x_unlabeld = x_train[np.where(unlabeld_index)[0], ...]\n",
        "\n",
        "x_train = x_train[np.where(~unlabeld_index)[0], ...]\n",
        "y_train = y_train[np.where(~unlabeld_index)[0], ...]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xJObMH2IBSW_"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "x_unlabeld = x_unlabeld.astype('float32') / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lJCk4Dl3ApwG"
      },
      "outputs": [],
      "source": [
        "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdM1DXorH9eJ",
        "outputId": "03fb36e0-daaf-4583-c997-9a413b976fad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.051293306\n",
            "0.0\n",
            "0.0\n"
          ]
        }
      ],
      "source": [
        "# examples of categorical crossentropy\n",
        "cce = keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "# a labeled data from the second class\n",
        "y_true = [[0, 1, 0, 0]]\n",
        "y_pred = [[0.05, 0.95, 0, 0]]\n",
        "print(cce(y_true, y_pred).numpy())\n",
        "\n",
        "# an ulabeled data\n",
        "y_true = [[0, 0, 0, 0]]\n",
        "y_pred = [[0.05, 0.95, 0, 0]]\n",
        "print(cce(y_true, y_pred).numpy())\n",
        "\n",
        "# another ulabeled data\n",
        "y_true = [[0, 0, 0, 0]]\n",
        "y_pred = [[0.1, 0.4, 0.3, 0.2]]\n",
        "print(cce(y_true, y_pred).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4x83mWHNV1D"
      },
      "source": [
        "# Part A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3YFIgMl_85b",
        "outputId": "63757a38-d8da-48aa-a66e-f42d49df8cde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 28, 28, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 10, 10, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 10, 10, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                16010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 81,962\n",
            "Trainable params: 81,770\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=x_train[0].shape))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPool2D())\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPool2D())\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqsKapLDUyw7",
        "outputId": "8ffe98ea-2325-4163-9aee-b066be455cda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "4/4 [==============================] - 10s 383ms/step - loss: 3.1646 - accuracy: 0.0750 - val_loss: 2.3022 - val_accuracy: 0.1027\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 0s 161ms/step - loss: 1.7429 - accuracy: 0.3800 - val_loss: 2.2946 - val_accuracy: 0.1039\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 0s 159ms/step - loss: 1.2589 - accuracy: 0.5350 - val_loss: 2.2842 - val_accuracy: 0.1122\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 0s 155ms/step - loss: 1.0160 - accuracy: 0.6850 - val_loss: 2.2765 - val_accuracy: 0.1600\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.7904 - accuracy: 0.7700 - val_loss: 2.2725 - val_accuracy: 0.1451\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 0.5779 - accuracy: 0.8550 - val_loss: 2.2678 - val_accuracy: 0.1470\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 0.4057 - accuracy: 0.9350 - val_loss: 2.2640 - val_accuracy: 0.1612\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 0.3089 - accuracy: 0.9400 - val_loss: 2.2606 - val_accuracy: 0.1612\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 0.2334 - accuracy: 0.9750 - val_loss: 2.2584 - val_accuracy: 0.1684\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.1669 - accuracy: 0.9850 - val_loss: 2.2568 - val_accuracy: 0.1805\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 0.1326 - accuracy: 0.9900 - val_loss: 2.2555 - val_accuracy: 0.1874\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 0.1043 - accuracy: 1.0000 - val_loss: 2.2551 - val_accuracy: 0.1878\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 0.0868 - accuracy: 1.0000 - val_loss: 2.2559 - val_accuracy: 0.1818\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 0.0586 - accuracy: 1.0000 - val_loss: 2.2580 - val_accuracy: 0.1670\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 2.2600 - val_accuracy: 0.1550\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 2.2608 - val_accuracy: 0.1507\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 0.0415 - accuracy: 0.9950 - val_loss: 2.2600 - val_accuracy: 0.1566\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 2.2613 - val_accuracy: 0.1704\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.0624 - accuracy: 0.9950 - val_loss: 2.2587 - val_accuracy: 0.1642\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 0.0548 - accuracy: 0.9950 - val_loss: 2.2542 - val_accuracy: 0.1629\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb1a66ea490>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    validation_data=(x_test, y_test)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qbnmk-nNadd"
      },
      "source": [
        "# Part B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3hgTAqvEVvOQ"
      },
      "outputs": [],
      "source": [
        "x_rotated = np.zeros_like(x_unlabeld)\n",
        "y_rotated = np.zeros((x_unlabeld.shape[0],))\n",
        "for i in range(x_rotated.shape[0]):\n",
        "    k = random.randint(0, 3)\n",
        "    x_rotated[i] = np.rot90(x_unlabeld[i], k)\n",
        "    y_rotated[i] = k\n",
        "\n",
        "y_rotated = keras.utils.to_categorical(y_rotated, num_classes=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ5bzGjzWsHZ",
        "outputId": "c8737be5-2d7b-48c1-9c9b-dcb442fe6fca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 28, 28, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 14, 14, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 12, 12, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 10, 10, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 10, 10, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 6404      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 72,356\n",
            "Trainable params: 72,164\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=x_train[0].shape))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPool2D())\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPool2D())\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(4, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3pi7AOsWwrx",
        "outputId": "09e8e3cf-c5f6-4710-8366-ca4866f04188"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "779/779 [==============================] - 5s 6ms/step - loss: 1.1743 - accuracy: 0.5062\n",
            "Epoch 2/20\n",
            "779/779 [==============================] - 5s 6ms/step - loss: 1.0438 - accuracy: 0.5725\n",
            "Epoch 3/20\n",
            "779/779 [==============================] - 5s 6ms/step - loss: 0.9663 - accuracy: 0.6105\n",
            "Epoch 4/20\n",
            "779/779 [==============================] - 5s 6ms/step - loss: 0.8910 - accuracy: 0.6415\n",
            "Epoch 5/20\n",
            "779/779 [==============================] - 5s 6ms/step - loss: 0.8297 - accuracy: 0.6688\n",
            "Epoch 6/20\n",
            "779/779 [==============================] - 5s 6ms/step - loss: 0.7774 - accuracy: 0.6946\n",
            "Epoch 7/20\n",
            "779/779 [==============================] - 5s 6ms/step - loss: 0.7316 - accuracy: 0.7118\n",
            "Epoch 8/20\n",
            "779/779 [==============================] - 5s 6ms/step - loss: 0.6909 - accuracy: 0.7310\n",
            "Epoch 9/20\n",
            "779/779 [==============================] - 5s 6ms/step - loss: 0.6473 - accuracy: 0.7492\n",
            "Epoch 10/20\n",
            "779/779 [==============================] - 5s 6ms/step - loss: 0.6130 - accuracy: 0.7635\n",
            "Epoch 11/20\n",
            "779/779 [==============================] - 5s 6ms/step - loss: 0.5778 - accuracy: 0.7768\n",
            "Epoch 12/20\n",
            "779/779 [==============================] - 5s 6ms/step - loss: 0.5447 - accuracy: 0.7904\n",
            "Epoch 13/20\n",
            "779/779 [==============================] - 5s 6ms/step - loss: 0.5075 - accuracy: 0.8057\n",
            "Epoch 14/20\n",
            "779/779 [==============================] - 5s 6ms/step - loss: 0.4851 - accuracy: 0.8139\n",
            "Epoch 15/20\n",
            "779/779 [==============================] - 5s 6ms/step - loss: 0.4490 - accuracy: 0.8290\n",
            "Epoch 16/20\n",
            "779/779 [==============================] - 5s 7ms/step - loss: 0.4254 - accuracy: 0.8382\n",
            "Epoch 17/20\n",
            "779/779 [==============================] - 5s 6ms/step - loss: 0.3969 - accuracy: 0.8478\n",
            "Epoch 18/20\n",
            "779/779 [==============================] - 5s 6ms/step - loss: 0.3724 - accuracy: 0.8591\n",
            "Epoch 19/20\n",
            "779/779 [==============================] - 5s 6ms/step - loss: 0.3546 - accuracy: 0.8658\n",
            "Epoch 20/20\n",
            "779/779 [==============================] - 5s 6ms/step - loss: 0.3301 - accuracy: 0.8751\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb1a631f9d0>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    x_rotated, y_rotated,\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KS2ePSRganiU",
        "outputId": "3fd11c6e-0adc-4ffb-f30c-d7fce4544620"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4_input (InputLayer)  [(None, 32, 32, 3)]      0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 28, 28, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 14, 14, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 12, 12, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 10, 10, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 10, 10, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                16010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 81,962\n",
            "Trainable params: 81,770\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_2 = keras.Model(inputs=model.inputs, outputs=layers.Dense(10, activation='softmax')(model.layers[-2].output))\n",
        "\n",
        "model_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mUy0gRF18El",
        "outputId": "7de8a6be-f9fe-4de9-bf19-45f7f2e2c9c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "4/4 [==============================] - 1s 313ms/step - loss: 2.6799 - accuracy: 0.1250 - val_loss: 2.7197 - val_accuracy: 0.0932\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 2.5771 - accuracy: 0.1500 - val_loss: 2.6918 - val_accuracy: 0.0968\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 2.4695 - accuracy: 0.1700 - val_loss: 2.6675 - val_accuracy: 0.1019\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 2.3794 - accuracy: 0.1950 - val_loss: 2.6424 - val_accuracy: 0.1070\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 2.3077 - accuracy: 0.2200 - val_loss: 2.6177 - val_accuracy: 0.1115\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 2.2348 - accuracy: 0.2300 - val_loss: 2.5935 - val_accuracy: 0.1175\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 2.1851 - accuracy: 0.2600 - val_loss: 2.5698 - val_accuracy: 0.1238\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 2.1106 - accuracy: 0.2850 - val_loss: 2.5479 - val_accuracy: 0.1291\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 2.0600 - accuracy: 0.3050 - val_loss: 2.5270 - val_accuracy: 0.1334\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 1.9886 - accuracy: 0.3250 - val_loss: 2.5075 - val_accuracy: 0.1376\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 1.9312 - accuracy: 0.3400 - val_loss: 2.4887 - val_accuracy: 0.1414\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 1.8780 - accuracy: 0.3650 - val_loss: 2.4706 - val_accuracy: 0.1457\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 1.8350 - accuracy: 0.3800 - val_loss: 2.4528 - val_accuracy: 0.1515\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 1.7625 - accuracy: 0.3950 - val_loss: 2.4355 - val_accuracy: 0.1558\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 1.7290 - accuracy: 0.3850 - val_loss: 2.4193 - val_accuracy: 0.1609\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 1s 181ms/step - loss: 1.6734 - accuracy: 0.4400 - val_loss: 2.4039 - val_accuracy: 0.1655\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 1.6333 - accuracy: 0.4800 - val_loss: 2.3897 - val_accuracy: 0.1694\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 1.5871 - accuracy: 0.4800 - val_loss: 2.3760 - val_accuracy: 0.1738\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 1.5356 - accuracy: 0.5350 - val_loss: 2.3630 - val_accuracy: 0.1790\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 1.5102 - accuracy: 0.5350 - val_loss: 2.3494 - val_accuracy: 0.1842\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb1a617d940>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_2.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_2.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    validation_data=(x_test, y_test)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtnxQ0e1NfQh"
      },
      "source": [
        "# Part C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dUCkbq42Bzh2"
      },
      "outputs": [],
      "source": [
        "x_train_concat = np.concatenate((x_train, x_rotated), axis=0)\n",
        "\n",
        "y_train_classification = np.concatenate((y_train, np.zeros((x_rotated.shape[0], 10))), axis=0)\n",
        "y_train_rotation = np.concatenate((np.array([[1, 0, 0, 0]] * x_train.shape[0]), y_rotated), axis=0) # I used [1, 0, 0, 0] (is 0) for the rotation of labeled data because they are not rotated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6fyDy8uEjDm",
        "outputId": "0f363a3f-6bd1-40a9-f8cc-e987c3428ccc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_15\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_8 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 30, 30, 32)   896         ['input_8[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 28, 28, 32)   9248        ['conv2d_28[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 28, 28, 32)  128         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling2d_14 (MaxPooling2D  (None, 14, 14, 32)  0           ['batch_normalization_14[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 12, 12, 64)   18496       ['max_pooling2d_14[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 64)   36928       ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 10, 10, 64)  256         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling2d_15 (MaxPooling2D  (None, 5, 5, 64)    0           ['batch_normalization_15[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " flatten_7 (Flatten)            (None, 1600)         0           ['max_pooling2d_15[0][0]']       \n",
            "                                                                                                  \n",
            " classification (Dense)         (None, 10)           16010       ['flatten_7[0][0]']              \n",
            "                                                                                                  \n",
            " rotation (Dense)               (None, 4)            6404        ['flatten_7[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 88,366\n",
            "Trainable params: 88,174\n",
            "Non-trainable params: 192\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "input = layers.Input(shape=x_train_concat[0].shape)\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu')(input)\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.MaxPool2D()(x)\n",
        "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.MaxPool2D()(x)\n",
        "out = layers.Flatten()(x)\n",
        "base_model = keras.Model(inputs=input, outputs=out)\n",
        "\n",
        "classification_layer = layers.Dense(10, activation='softmax', name='classification')(base_model.outputs[0])\n",
        "rotation_layer = layers.Dense(4, activation='softmax', name='rotation')(base_model.outputs[0])\n",
        "\n",
        "model = keras.Model(inputs=base_model.inputs, outputs=[classification_layer, rotation_layer])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cA4Kmz0gFgaW",
        "outputId": "893de822-0ce2-4b96-9443-c860e272feb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 3.0603 - classification_loss: 0.0126 - rotation_loss: 1.7988 - classification_accuracy: 0.0551 - rotation_accuracy: 0.2663 - val_loss: 295.4293 - val_classification_loss: 2.9543 - val_rotation_loss: 0.0000e+00 - val_classification_accuracy: 0.1065 - val_rotation_accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.8126 - classification_loss: 0.0123 - rotation_loss: 1.5788 - classification_accuracy: 0.0515 - rotation_accuracy: 0.2622 - val_loss: 310.0349 - val_classification_loss: 3.1003 - val_rotation_loss: 0.0000e+00 - val_classification_accuracy: 0.0989 - val_rotation_accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.7185 - classification_loss: 0.0123 - rotation_loss: 1.4901 - classification_accuracy: 0.0507 - rotation_accuracy: 0.2595 - val_loss: 305.9677 - val_classification_loss: 3.0597 - val_rotation_loss: 0.0000e+00 - val_classification_accuracy: 0.0993 - val_rotation_accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.6941 - classification_loss: 0.0125 - rotation_loss: 1.4463 - classification_accuracy: 0.0542 - rotation_accuracy: 0.2587 - val_loss: 304.0860 - val_classification_loss: 3.0409 - val_rotation_loss: 0.0000e+00 - val_classification_accuracy: 0.0994 - val_rotation_accuracy: 0.0000e+00\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.7241 - classification_loss: 0.0129 - rotation_loss: 1.4315 - classification_accuracy: 0.0545 - rotation_accuracy: 0.2590 - val_loss: 306.8434 - val_classification_loss: 3.0684 - val_rotation_loss: 0.0000e+00 - val_classification_accuracy: 0.0996 - val_rotation_accuracy: 0.0000e+00\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.7357 - classification_loss: 0.0131 - rotation_loss: 1.4256 - classification_accuracy: 0.0561 - rotation_accuracy: 0.2610 - val_loss: 327.5291 - val_classification_loss: 3.2753 - val_rotation_loss: 0.0000e+00 - val_classification_accuracy: 0.1005 - val_rotation_accuracy: 0.0000e+00\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.7634 - classification_loss: 0.0134 - rotation_loss: 1.4234 - classification_accuracy: 0.0577 - rotation_accuracy: 0.2616 - val_loss: 327.2544 - val_classification_loss: 3.2725 - val_rotation_loss: 0.0000e+00 - val_classification_accuracy: 0.1011 - val_rotation_accuracy: 0.0000e+00\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.7868 - classification_loss: 0.0137 - rotation_loss: 1.4210 - classification_accuracy: 0.0592 - rotation_accuracy: 0.2623 - val_loss: 335.0784 - val_classification_loss: 3.3508 - val_rotation_loss: 0.0000e+00 - val_classification_accuracy: 0.1012 - val_rotation_accuracy: 0.0000e+00\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.8120 - classification_loss: 0.0139 - rotation_loss: 1.4229 - classification_accuracy: 0.0604 - rotation_accuracy: 0.2620 - val_loss: 349.5417 - val_classification_loss: 3.4954 - val_rotation_loss: 0.0000e+00 - val_classification_accuracy: 0.0967 - val_rotation_accuracy: 0.0000e+00\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.8468 - classification_loss: 0.0142 - rotation_loss: 1.4232 - classification_accuracy: 0.0607 - rotation_accuracy: 0.2601 - val_loss: 354.2196 - val_classification_loss: 3.5422 - val_rotation_loss: 0.0000e+00 - val_classification_accuracy: 0.1006 - val_rotation_accuracy: 0.0000e+00\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.8685 - classification_loss: 0.0145 - rotation_loss: 1.4211 - classification_accuracy: 0.0639 - rotation_accuracy: 0.2636 - val_loss: 361.3281 - val_classification_loss: 3.6133 - val_rotation_loss: 0.0000e+00 - val_classification_accuracy: 0.1007 - val_rotation_accuracy: 0.0000e+00\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.8987 - classification_loss: 0.0148 - rotation_loss: 1.4217 - classification_accuracy: 0.0632 - rotation_accuracy: 0.2622 - val_loss: 371.2409 - val_classification_loss: 3.7124 - val_rotation_loss: 0.0000e+00 - val_classification_accuracy: 0.0999 - val_rotation_accuracy: 0.0000e+00\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 2.9238 - classification_loss: 0.0150 - rotation_loss: 1.4207 - classification_accuracy: 0.0647 - rotation_accuracy: 0.2602 - val_loss: 370.7194 - val_classification_loss: 3.7072 - val_rotation_loss: 0.0000e+00 - val_classification_accuracy: 0.0968 - val_rotation_accuracy: 0.0000e+00\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.9608 - classification_loss: 0.0154 - rotation_loss: 1.4198 - classification_accuracy: 0.0663 - rotation_accuracy: 0.2637 - val_loss: 384.3430 - val_classification_loss: 3.8434 - val_rotation_loss: 0.0000e+00 - val_classification_accuracy: 0.0959 - val_rotation_accuracy: 0.0000e+00\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.9876 - classification_loss: 0.0157 - rotation_loss: 1.4218 - classification_accuracy: 0.0665 - rotation_accuracy: 0.2619 - val_loss: 390.9147 - val_classification_loss: 3.9091 - val_rotation_loss: 0.0000e+00 - val_classification_accuracy: 0.0992 - val_rotation_accuracy: 0.0000e+00\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 3.0051 - classification_loss: 0.0158 - rotation_loss: 1.4218 - classification_accuracy: 0.0669 - rotation_accuracy: 0.2615 - val_loss: 404.3054 - val_classification_loss: 4.0431 - val_rotation_loss: 0.0000e+00 - val_classification_accuracy: 0.0990 - val_rotation_accuracy: 0.0000e+00\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 3.0422 - classification_loss: 0.0162 - rotation_loss: 1.4236 - classification_accuracy: 0.0688 - rotation_accuracy: 0.2585 - val_loss: 408.4861 - val_classification_loss: 4.0849 - val_rotation_loss: 0.0000e+00 - val_classification_accuracy: 0.0960 - val_rotation_accuracy: 0.0000e+00\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 3.0911 - classification_loss: 0.0167 - rotation_loss: 1.4215 - classification_accuracy: 0.0686 - rotation_accuracy: 0.2623 - val_loss: 417.8919 - val_classification_loss: 4.1789 - val_rotation_loss: 0.0000e+00 - val_classification_accuracy: 0.0979 - val_rotation_accuracy: 0.0000e+00\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 3.1083 - classification_loss: 0.0168 - rotation_loss: 1.4234 - classification_accuracy: 0.0706 - rotation_accuracy: 0.2607 - val_loss: 426.8234 - val_classification_loss: 4.2682 - val_rotation_loss: 0.0000e+00 - val_classification_accuracy: 0.0977 - val_rotation_accuracy: 0.0000e+00\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 3.1469 - classification_loss: 0.0172 - rotation_loss: 1.4253 - classification_accuracy: 0.0709 - rotation_accuracy: 0.2605 - val_loss: 425.1845 - val_classification_loss: 4.2518 - val_rotation_loss: 0.0000e+00 - val_classification_accuracy: 0.0982 - val_rotation_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6adc506eb0>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(\n",
        "    loss={\n",
        "        'classification': 'categorical_crossentropy',\n",
        "        'rotation': 'categorical_crossentropy'\n",
        "    },\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4, decay=1e-4 / 20),\n",
        "    metrics=['accuracy'],\n",
        "    loss_weights={\n",
        "        'classification': 100,\n",
        "        'rotation': 1\n",
        "    }\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    x_train_concat, [y_train_classification, y_train_rotation],\n",
        "    batch_size=64,\n",
        "    epochs=20,\n",
        "    validation_data=(x_test, {'classification': y_test})\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
